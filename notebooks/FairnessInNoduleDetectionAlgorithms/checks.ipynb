{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double check sample numbers are correct for training SUMMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/john/Projects/SOTAEvaluationNoduleDetection\n",
      "Training scans: 4753\n",
      "Training metadata: 6145\n",
      "Training unique metadata scans: 2672\n",
      "Training excludes: 1428\n",
      "Validation scans: 297\n",
      "Validation metadata: 387\n",
      "Validation unique metadata scans: 173\n",
      "Validation excludes: 79\n",
      "Test scans: 891\n",
      "Test metadata: 1087\n",
      "Test unique metadata scans: 458\n",
      "Test excludes: 288\n",
      "Total scans in all datasets: 5941\n",
      "Total metadata in all datasets: 7619\n",
      "Unique scans in metadata: 3303\n",
      "Total excludes in all datasets: 1795\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "workspace_path = Path(os.getcwd()).parent.parent\n",
    "\n",
    "print(workspace_path)\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    'Training' : {},\n",
    "    'Validation': {},\n",
    "    'Test' : {}\n",
    "}\n",
    "\n",
    "for ds in datasets:\n",
    "\n",
    "    datasets[ds]['scans'] = pd.read_csv(f'{workspace_path}/metadata/summit/partial/{ds}_scans.csv')\n",
    "    datasets[ds]['metadata'] = pd.read_csv(f'{workspace_path}/metadata/summit/partial/{ds}_metadata.csv').assign(scan_id=lambda df: df.participant_id + '_Y0_BASELINE_A')\n",
    "    datasets[ds]['excludes'] = pd.read_csv(f'{workspace_path}/metadata/summit/partial/{ds}_excludes.csv').assign(scan_id=lambda df: df.participant_id + '_Y0_BASELINE_A')\n",
    "\n",
    "\n",
    "    print(f'{ds} scans: {datasets[ds][\"scans\"].shape[0]}')\n",
    "    print(f'{ds} metadata: {datasets[ds][\"metadata\"].shape[0]}')\n",
    "    print(f'{ds} unique metadata scans: {datasets[ds][\"metadata\"][\"scan_id\"].nunique()}')\n",
    "    print(f'{ds} excludes: {datasets[ds][\"excludes\"].shape[0]}')\n",
    "\n",
    "print('Total scans in all datasets:', sum([datasets[ds]['scans'].shape[0] for ds in datasets]))\n",
    "print('Total metadata in all datasets:', sum([datasets[ds]['metadata'].shape[0] for ds in datasets]))\n",
    "print('Unique scans in metadata:', sum([datasets[ds]['metadata']['scan_id'].nunique() for ds in datasets]))\n",
    "print('Total excludes in all datasets:', sum([datasets[ds]['excludes'].shape[0] for ds in datasets]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scans fields: Index(['scan_id'], dtype='object')\n",
      "Metadata fields: Index(['form_instance_id', 'form_instance_status', 'participant_id',\n",
      "       'form_instance_index', 'nodule_brock_score', 'nodule_category',\n",
      "       'nodule_diameter_mm', 'nodule_lesion_id', 'nodule_lung_rads',\n",
      "       'nodule_mass', 'nodule_mass_core', 'nodule_mass_double_time_core',\n",
      "       'nodule_mass_doubling_time', 'nodule_reliable_segment', 'nodule_site',\n",
      "       'nodule_size_volume_cub_mm', 'nodule_slice_number',\n",
      "       'nodule_spiculation', 'nodule_subsolid_major_axis_diameter',\n",
      "       'nodule_type', 'nodule_volume_core', 'nodule_volume_doubling_time',\n",
      "       'nodule_volume_percentage_change',\n",
      "       'nodule_volume_volume_double_time_core', 'nodule_x_coordinate',\n",
      "       'nodule_y_coordinate', 'nodule_z_coordinate',\n",
      "       'radiology_report_management_plan_value', 'management_plan',\n",
      "       'radiology_report_malignancy_diagnosis',\n",
      "       'radiology_report_malignancy_criteria',\n",
      "       'radiology_report_malignancy_primary_order',\n",
      "       'radiology_report_scans_transfer_state', 'gender', 'age_group',\n",
      "       'ethnic_group', 'radiology_report_lesions_to_exclude', 'scan_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# What fields are in the datasets\n",
    "print('Scans fields:', datasets['Training']['scans'].columns)\n",
    "print('Metadata fields:', datasets['Training']['metadata'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset.json for MONAI Detection\n",
    "\n",
    "As the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 2845\n",
      "Training boxes: 6532\n",
      "Test: 891\n",
      "Test boxes: 1087\n"
     ]
    }
   ],
   "source": [
    "dataset_json = {\n",
    "    'Training': [],\n",
    "    'Test': []\n",
    "}\n",
    "\n",
    "for ds in datasets.keys():\n",
    "\n",
    "    # for training just add positive samples .. iterate over metadata\n",
    "    \n",
    "    if ds == 'Training' or ds == 'Validation':\n",
    "        scan_ids = datasets[ds]['metadata']['scan_id'].sort_values().unique().tolist()\n",
    "    \n",
    "    if ds == 'Test':\n",
    "        scan_ids = datasets[ds]['scans']['scan_id'].sort_values().tolist()\n",
    "\n",
    "    for scan_id in scan_ids:\n",
    "        annotation_dict = {\"box\" : [], \"image\" : f\"{scan_id.split('_')[0]}/{scan_id}.nii.gz\", \"label\" : []}\n",
    "\n",
    "        metadata = datasets[ds]['metadata'][datasets[ds]['metadata']['scan_id'] == scan_id]\n",
    "\n",
    "        for idx, row in metadata.iterrows():\n",
    "            annotation_dict['box'].append([\n",
    "                row['nodule_x_coordinate'],\n",
    "                row['nodule_y_coordinate'],\n",
    "                row['nodule_z_coordinate'],\n",
    "                row['nodule_diameter_mm'],\n",
    "                row['nodule_diameter_mm'],\n",
    "                row['nodule_diameter_mm']\n",
    "            ])\n",
    "\n",
    "            annotation_dict['label'].append(0)\n",
    "\n",
    "        dataset_json['Test' if ds == 'Test' else 'Training'].append(annotation_dict)\n",
    "\n",
    "# Check numbers in json\n",
    "print('Training:', len(dataset_json['Training']))\n",
    "print('Training boxes:', sum([len(x['box']) for x in dataset_json['Training']]))\n",
    "\n",
    "print('Test:', len(dataset_json['Test']))\n",
    "print('Test boxes:', sum([len(x['box']) for x in dataset_json['Test']]))\n",
    "\n",
    "# Save json\n",
    "import json\n",
    "with open(f'{workspace_path}/models/detection/datasplits/summit/partial/dataset_partial.json', 'w') as f:\n",
    "    json.dump(dataset_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that the files exist on the server before starting training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permissions</th>\n",
       "      <th>links</th>\n",
       "      <th>owner</th>\n",
       "      <th>group</th>\n",
       "      <th>size</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>1</td>\n",
       "      <td>jmccabe</td>\n",
       "      <td>summit</td>\n",
       "      <td>107275</td>\n",
       "      <td>Feb</td>\n",
       "      <td>8</td>\n",
       "      <td>16:14</td>\n",
       "      <td>listing.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>1</td>\n",
       "      <td>jmccabe</td>\n",
       "      <td>summit</td>\n",
       "      <td>315490</td>\n",
       "      <td>Feb</td>\n",
       "      <td>9</td>\n",
       "      <td>14:59</td>\n",
       "      <td>listings.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>1</td>\n",
       "      <td>jmccabe</td>\n",
       "      <td>summit</td>\n",
       "      <td>185564258</td>\n",
       "      <td>Sep</td>\n",
       "      <td>6</td>\n",
       "      <td>2023</td>\n",
       "      <td>summit-2222-djr_Y0_BASELINE_A.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>1</td>\n",
       "      <td>jmccabe</td>\n",
       "      <td>summit</td>\n",
       "      <td>215327282</td>\n",
       "      <td>Sep</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>summit-2223-yts_Y0_BASELINE_A.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>1</td>\n",
       "      <td>jmccabe</td>\n",
       "      <td>summit</td>\n",
       "      <td>175178964</td>\n",
       "      <td>Sep</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>summit-2224-eju_Y0_BASELINE_A.nii.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  permissions links    owner   group       size month day   time  \\\n",
       "1  -rw-r--r--     1  jmccabe  summit     107275   Feb   8  16:14   \n",
       "2  -rw-r--r--     1  jmccabe  summit     315490   Feb   9  14:59   \n",
       "3  -rw-r--r--     1  jmccabe  summit  185564258   Sep   6   2023   \n",
       "4  -rw-r--r--     1  jmccabe  summit  215327282   Sep   7   2023   \n",
       "5  -rw-r--r--     1  jmccabe  summit  175178964   Sep   7   2023   \n",
       "\n",
       "                               filename  \n",
       "1                            listing.sh  \n",
       "2                          listings.txt  \n",
       "3  summit-2222-djr_Y0_BASELINE_A.nii.gz  \n",
       "4  summit-2223-yts_Y0_BASELINE_A.nii.gz  \n",
       "5  summit-2224-eju_Y0_BASELINE_A.nii.gz  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed Detection: 0\n",
      "Training size: 472.614774511 GB\n"
     ]
    }
   ],
   "source": [
    "# Detection\n",
    "\n",
    "server_listings = open('detection_listings.txt', 'r').readlines()\n",
    "server_listings = [x.replace('/','').replace('\\n','') for x in server_listings]\n",
    "\n",
    "\n",
    "# Split each line into columns\n",
    "columns = [line.split() for line in server_listings]\n",
    "\n",
    "# Create a dataframe from the columns\n",
    "df = pd.DataFrame(columns).drop(0,axis=0)\n",
    "\n",
    "# Set column names\n",
    "df.columns = ['permissions', 'links', 'owner', 'group', 'size', 'month', 'day', 'time', 'filename']\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "\n",
    "missed = 0\n",
    "for ds in datasets:\n",
    "    for image in dataset_json['Test' if ds == 'Test' else 'Training']:\n",
    "        image_id = image['image'].split('/')[1]\n",
    "        if image_id not in df.filename.values:\n",
    "            print(f'Image {image_id} not found in server listings')\n",
    "            missed += 1\n",
    "        else:\n",
    "            # update listings df with dataset\n",
    "            df.loc[df.filename.str.contains(image_id), 'dataset'] = 'Test' if ds == 'Test' else 'Training'\n",
    "            \n",
    "print('Missed Detection:', missed)\n",
    "# Print the size of the training data\n",
    "bytes = df[df.dataset == 'Training']['size'].astype(int).sum()\n",
    "print('Training size:', bytes/1e9, 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permissions</th>\n",
       "      <th>links</th>\n",
       "      <th>owner</th>\n",
       "      <th>group</th>\n",
       "      <th>size</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drwxr-sr-x</td>\n",
       "      <td>2</td>\n",
       "      <td>jmccabe</td>\n",
       "      <td>summit</td>\n",
       "      <td>307200</td>\n",
       "      <td>Mar</td>\n",
       "      <td>20</td>\n",
       "      <td>15:39</td>\n",
       "      <td>exclusions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>1</td>\n",
       "      <td>jmccabe</td>\n",
       "      <td>summit</td>\n",
       "      <td>0</td>\n",
       "      <td>Apr</td>\n",
       "      <td>24</td>\n",
       "      <td>12:37</td>\n",
       "      <td>grt123_listings.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>1</td>\n",
       "      <td>jmccabe</td>\n",
       "      <td>summit</td>\n",
       "      <td>22270688</td>\n",
       "      <td>Feb</td>\n",
       "      <td>9</td>\n",
       "      <td>16:01</td>\n",
       "      <td>summit-2223-yts_Y0_BASELINE_A_clean.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>1</td>\n",
       "      <td>jmccabe</td>\n",
       "      <td>summit</td>\n",
       "      <td>160</td>\n",
       "      <td>Feb</td>\n",
       "      <td>9</td>\n",
       "      <td>16:01</td>\n",
       "      <td>summit-2223-yts_Y0_BASELINE_A_label.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>1</td>\n",
       "      <td>jmccabe</td>\n",
       "      <td>summit</td>\n",
       "      <td>16011992</td>\n",
       "      <td>Feb</td>\n",
       "      <td>8</td>\n",
       "      <td>23:04</td>\n",
       "      <td>summit-2224-gak_Y0_BASELINE_A_clean.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  permissions links    owner   group      size month day   time  \\\n",
       "1  drwxr-sr-x     2  jmccabe  summit    307200   Mar  20  15:39   \n",
       "2  -rw-r--r--     1  jmccabe  summit         0   Apr  24  12:37   \n",
       "3  -rw-r--r--     1  jmccabe  summit  22270688   Feb   9  16:01   \n",
       "4  -rw-r--r--     1  jmccabe  summit       160   Feb   9  16:01   \n",
       "5  -rw-r--r--     1  jmccabe  summit  16011992   Feb   8  23:04   \n",
       "\n",
       "                                  filename  \n",
       "1                               exclusions  \n",
       "2                      grt123_listings.txt  \n",
       "3  summit-2223-yts_Y0_BASELINE_A_clean.npy  \n",
       "4  summit-2223-yts_Y0_BASELINE_A_label.npy  \n",
       "5  summit-2224-gak_Y0_BASELINE_A_clean.npy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed GRT123: 0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "# Grt123\n",
    "\n",
    "server_listings = open('grt123_listings.txt', 'r').readlines()\n",
    "server_listings = [x.replace('\\n','') for x in server_listings]\n",
    "\n",
    "\n",
    "# Split each line into columns\n",
    "columns = [line.split() for line in server_listings]\n",
    "\n",
    "# Create a dataframe from the columns\n",
    "df = pd.DataFrame(columns).drop(0,axis=0)\n",
    "\n",
    "# Set column names\n",
    "df.columns = ['permissions', 'links', 'owner', 'group', 'size', 'month', 'day', 'time', 'filename']\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "scans_on_server = df[df.filename.str.contains('_clean.npy')].filename.str.replace('_clean.npy','').values\n",
    "\n",
    "missed = 0\n",
    "for ds in datasets:\n",
    "    \n",
    "    for scan_id in datasets[ds]['scans']['scan_id'].values:\n",
    "\n",
    "        \n",
    "        if scan_id not in scans_on_server:\n",
    "            print(f'Scan {scan_id} not found in server listings')\n",
    "            missed += 1\n",
    "\n",
    "        else:\n",
    "            # update listings df with dataset\n",
    "            df.loc[df.filename.str.contains(scan_id), 'dataset'] = ds\n",
    "\n",
    "print('Missed GRT123:', missed)\n",
    "\n",
    "# Print the size of the training data\n",
    "bytes = df[df.dataset == 'Training']['size'].astype(int).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 86.670393324 GB\n"
     ]
    }
   ],
   "source": [
    "print('Training size:', bytes/1e9, 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "test_balanced training includes: 2466\n",
      "test_balanced training excludes: 4075\n",
      "test_balanced training includes percentage: 37.7\n",
      "test_balanced training total: 6541\n",
      "********************\n",
      "test_balanced validation includes: 130\n",
      "test_balanced validation excludes: 247\n",
      "test_balanced validation includes percentage: 34.48\n",
      "test_balanced validation total: 377\n",
      "********************\n",
      "test_balanced test includes: 230\n",
      "test_balanced test excludes: 469\n",
      "test_balanced test includes percentage: 32.9\n",
      "test_balanced test total: 699\n",
      "********************\n",
      "male_only training includes: 700\n",
      "male_only training excludes: 1418\n",
      "male_only training includes percentage: 33.05\n",
      "male_only training total: 2118\n",
      "********************\n",
      "male_only validation includes: 52\n",
      "male_only validation excludes: 69\n",
      "male_only validation includes percentage: 42.98\n",
      "male_only validation total: 121\n",
      "********************\n",
      "male_only test includes: 162\n",
      "male_only test excludes: 318\n",
      "male_only test includes percentage: 33.75\n",
      "male_only test total: 480\n",
      "********************\n",
      "white_only training includes: 1750\n",
      "white_only training excludes: 2863\n",
      "white_only training includes percentage: 37.94\n",
      "white_only training total: 4613\n",
      "********************\n",
      "white_only validation includes: 120\n",
      "white_only validation excludes: 180\n",
      "white_only validation includes percentage: 40.0\n",
      "white_only validation total: 300\n",
      "********************\n",
      "white_only test includes: 414\n",
      "white_only test excludes: 691\n",
      "white_only test includes percentage: 37.47\n",
      "white_only test total: 1105\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check nodule includes and exclude counts\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "workspace_path = Path(os.getcwd()).parent.parent\n",
    "\n",
    "for flavour in ['test_balanced', 'male_only', 'white_only']:\n",
    "\n",
    "    for ds in ['training','validation','test']:\n",
    "\n",
    "        df = pd.read_csv(f'{workspace_path}/metadata/summit/{flavour}/{ds}_metadata.csv')\n",
    "\n",
    "        print('*'*20)\n",
    "        print(f'{flavour} {ds} includes:', df.management_plan[df.management_plan.isin(['3_MONTH_FOLLOW_UP_SCAN','URGENT_REFERRAL', 'ALWAYS_SCAN_AT_YEAR_1'])].count())\n",
    "        print(f'{flavour} {ds} excludes:', df.management_plan[df.management_plan.isin(['RANDOMISATION_AT_YEAR_1'])].count())\n",
    "        includes_percentage = df.management_plan[df.management_plan.isin(['3_MONTH_FOLLOW_UP_SCAN','URGENT_REFERRAL', 'ALWAYS_SCAN_AT_YEAR_1'])].count() / df.shape[0] * 100\n",
    "        print(f'{flavour} {ds} includes percentage:', round(includes_percentage,2))\n",
    "        print(f'{flavour} {ds} total:', df.shape[0])\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "flavour: test_balanced\n",
      "Scans: 594\n",
      "Gender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MALE      344\n",
       "FEMALE    250\n",
       "Name: participant_details_gender, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic Group\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Black                     198\n",
       "Asian or Asian British    198\n",
       "White                     198\n",
       "Name: lung_health_check_demographics_race_ethnicgroup, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodules\n",
      "Total: 699\n",
      "Gender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MALE      400\n",
       "FEMALE    299\n",
       "Name: gender, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic Group\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Black                     250\n",
       "White                     242\n",
       "Asian or Asian British    207\n",
       "Name: ethnic_group, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actionable Gender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MALE      120\n",
       "FEMALE    110\n",
       "Name: gender, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actionable Ethnic Group\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "White                     103\n",
       "Asian or Asian British     65\n",
       "Black                      62\n",
       "Name: ethnic_group, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "flavour: male_only\n",
      "Scans: 420\n",
      "Gender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MALE    420\n",
       "Name: participant_details_gender, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic Group\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "White                     140\n",
       "Asian or Asian British    140\n",
       "Black                     140\n",
       "Name: lung_health_check_demographics_race_ethnicgroup, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodules\n",
      "Total: 480\n",
      "Gender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MALE    480\n",
       "Name: gender, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic Group\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "White                     188\n",
       "Black                     171\n",
       "Asian or Asian British    121\n",
       "Name: ethnic_group, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actionable Gender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MALE    162\n",
       "Name: gender, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actionable Ethnic Group\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "White                     82\n",
       "Asian or Asian British    43\n",
       "Black                     37\n",
       "Name: ethnic_group, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "flavour: white_only\n",
      "Scans: 798\n",
      "Gender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FEMALE    399\n",
       "MALE      399\n",
       "Name: participant_details_gender, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic Group\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "White    798\n",
       "Name: lung_health_check_demographics_race_ethnicgroup, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodules\n",
      "Total: 1105\n",
      "Gender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MALE      553\n",
       "FEMALE    552\n",
       "Name: gender, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic Group\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "White    1105\n",
       "Name: ethnic_group, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actionable Gender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FEMALE    216\n",
       "MALE      198\n",
       "Name: gender, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actionable Ethnic Group\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "White    414\n",
       "Name: ethnic_group, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check nodule includes and exclude counts\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "workspace_path = Path(os.getcwd()).parent.parent\n",
    "\n",
    "for flavour in ['test_balanced', 'male_only', 'white_only']:\n",
    "\n",
    "    df = pd.read_csv(f'{workspace_path}/metadata/summit/{flavour}/test_scans_metadata.csv')\n",
    "    print('*'*20)\n",
    "    print(f'flavour: {flavour}')\n",
    "    print('Scans:', df.shape[0])\n",
    "    print('Gender')\n",
    "    display(df.participant_details_gender.value_counts())\n",
    "    print('Ethnic Group')\n",
    "    display(df.lung_health_check_demographics_race_ethnicgroup.value_counts())\n",
    "\n",
    "\n",
    "    # Check nodule includes and exclude counts\n",
    "    df = pd.read_csv(f'{workspace_path}/metadata/summit/{flavour}/test_metadata.csv').assign(actionable=lambda df: df.management_plan.isin(['3_MONTH_FOLLOW_UP_SCAN','URGENT_REFERRAL', 'ALWAYS_SCAN_AT_YEAR_1']))\n",
    "    \n",
    "    print('Nodules')\n",
    "    print('Total:', df.shape[0])\n",
    "    print('Gender')\n",
    "    display(df.gender.value_counts())\n",
    "    print('Ethnic Group')\n",
    "    display(df.ethnic_group.value_counts())\n",
    "    print('Actionable Gender')\n",
    "    display(df[df.actionable].gender.value_counts())\n",
    "    print('Actionable Ethnic Group')\n",
    "    display(df[df.actionable].ethnic_group.value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seriesuid</th>\n",
       "      <th>nodule_x_coordinate</th>\n",
       "      <th>nodule_y_coordinate</th>\n",
       "      <th>nodule_z_coordinate</th>\n",
       "      <th>coordX</th>\n",
       "      <th>coordY</th>\n",
       "      <th>coordZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summit-2294-pxb_Y0_BASELINE_A</td>\n",
       "      <td>-57.090</td>\n",
       "      <td>72.70</td>\n",
       "      <td>-168.30</td>\n",
       "      <td>76.210</td>\n",
       "      <td>181.20</td>\n",
       "      <td>89.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summit-2298-djm_Y0_BASELINE_A</td>\n",
       "      <td>-91.860</td>\n",
       "      <td>-53.27</td>\n",
       "      <td>-117.39</td>\n",
       "      <td>60.840</td>\n",
       "      <td>48.73</td>\n",
       "      <td>144.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summit-2323-kha_Y0_BASELINE_A</td>\n",
       "      <td>65.820</td>\n",
       "      <td>52.25</td>\n",
       "      <td>-129.88</td>\n",
       "      <td>193.320</td>\n",
       "      <td>168.25</td>\n",
       "      <td>88.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summit-2323-kha_Y0_BASELINE_A</td>\n",
       "      <td>53.860</td>\n",
       "      <td>81.70</td>\n",
       "      <td>-169.06</td>\n",
       "      <td>181.360</td>\n",
       "      <td>197.70</td>\n",
       "      <td>49.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>summit-2323-kha_Y0_BASELINE_A</td>\n",
       "      <td>96.625</td>\n",
       "      <td>66.25</td>\n",
       "      <td>-162.50</td>\n",
       "      <td>224.125</td>\n",
       "      <td>182.25</td>\n",
       "      <td>56.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>summit-9967-eya_Y0_BASELINE_A</td>\n",
       "      <td>-121.530</td>\n",
       "      <td>21.67</td>\n",
       "      <td>-205.95</td>\n",
       "      <td>38.470</td>\n",
       "      <td>145.17</td>\n",
       "      <td>122.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>summit-9967-eya_Y0_BASELINE_A</td>\n",
       "      <td>-40.440</td>\n",
       "      <td>21.33</td>\n",
       "      <td>-53.65</td>\n",
       "      <td>119.560</td>\n",
       "      <td>144.83</td>\n",
       "      <td>274.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>summit-9967-eya_Y0_BASELINE_A</td>\n",
       "      <td>-99.130</td>\n",
       "      <td>32.74</td>\n",
       "      <td>-93.57</td>\n",
       "      <td>60.870</td>\n",
       "      <td>156.24</td>\n",
       "      <td>234.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>summit-9967-rsb_Y0_BASELINE_A</td>\n",
       "      <td>105.240</td>\n",
       "      <td>21.78</td>\n",
       "      <td>-37.30</td>\n",
       "      <td>227.240</td>\n",
       "      <td>116.28</td>\n",
       "      <td>183.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>summit-9967-rsb_Y0_BASELINE_A</td>\n",
       "      <td>-69.680</td>\n",
       "      <td>41.25</td>\n",
       "      <td>-79.29</td>\n",
       "      <td>52.320</td>\n",
       "      <td>135.75</td>\n",
       "      <td>141.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         seriesuid  nodule_x_coordinate  nodule_y_coordinate  \\\n",
       "0    summit-2294-pxb_Y0_BASELINE_A              -57.090                72.70   \n",
       "1    summit-2298-djm_Y0_BASELINE_A              -91.860               -53.27   \n",
       "2    summit-2323-kha_Y0_BASELINE_A               65.820                52.25   \n",
       "3    summit-2323-kha_Y0_BASELINE_A               53.860                81.70   \n",
       "4    summit-2323-kha_Y0_BASELINE_A               96.625                66.25   \n",
       "..                             ...                  ...                  ...   \n",
       "694  summit-9967-eya_Y0_BASELINE_A             -121.530                21.67   \n",
       "695  summit-9967-eya_Y0_BASELINE_A              -40.440                21.33   \n",
       "696  summit-9967-eya_Y0_BASELINE_A              -99.130                32.74   \n",
       "697  summit-9967-rsb_Y0_BASELINE_A              105.240                21.78   \n",
       "698  summit-9967-rsb_Y0_BASELINE_A              -69.680                41.25   \n",
       "\n",
       "     nodule_z_coordinate   coordX  coordY   coordZ  \n",
       "0                -168.30   76.210  181.20   89.200  \n",
       "1                -117.39   60.840   48.73  144.610  \n",
       "2                -129.88  193.320  168.25   88.620  \n",
       "3                -169.06  181.360  197.70   49.440  \n",
       "4                -162.50  224.125  182.25   56.000  \n",
       "..                   ...      ...     ...      ...  \n",
       "694              -205.95   38.470  145.17  122.425  \n",
       "695               -53.65  119.560  144.83  274.725  \n",
       "696               -93.57   60.870  156.24  234.805  \n",
       "697               -37.30  227.240  116.28  183.075  \n",
       "698               -79.29   52.320  135.75  141.085  \n",
       "\n",
       "[699 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ticnet_annotations = pd.read_csv('/Users/john/Projects/TiCNet-main/annotations/summit/test_balanced/test_metadata.csv')\n",
    "metadata = pd.read_csv('/Users/john/Projects/SOTAEvaluationNoduleDetection/metadata/summit/test_balanced/test_metadata.csv').assign(seriesuid=lambda df: df.participant_id + '_Y0_BASELINE_A')\n",
    "\n",
    "metadata = metadata.assign(seriesuid_counter=lambda df: df.groupby('seriesuid').cumcount() + 1)\n",
    "ticnet_annotations = ticnet_annotations.assign(seriesuid_counter=lambda df: df.groupby('seriesuid').cumcount() + 1)\n",
    "\n",
    "df = pd.merge(metadata, ticnet_annotations, on=['seriesuid','seriesuid_counter'], how='outer')\n",
    "\n",
    "df['diameter_proportion'] = df['nodule_diameter_mm'] / df['diameter_mm']\n",
    "\n",
    "df['diameter_proportion'].min(), df['diameter_proportion'].max()\n",
    "\n",
    "df[[\n",
    "    'seriesuid',\n",
    "    'nodule_x_coordinate',\n",
    "    'nodule_y_coordinate',\n",
    "    'nodule_z_coordinate',\n",
    "    'coordX',\n",
    "    'coordY',\n",
    "    'coordZ',\n",
    "    ]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
